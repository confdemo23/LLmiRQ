Reduce allocation of objects in metrics
We use JMX and o.a.h.metrics2 to do some metrics on regions, tables, region servers and cluster. We use MetricsInfo to show the information of metrics, and we use Interns to cache MetricsInfo objects because it won&amp;apos;t be changed.
However, in Interns there are some static values to limit the max cached objects. We can only cache 2010 metrics, but we have dozens of metrics for one region and we have some RS-level metrics in each RS and all metrics for all regions will be saved in master. So each server will have thousands of metrics, and we can not cache most of them. When we collect metrics by JMX, we will create many objects which can be avoid. It increases the pressure of GC and JMX has some caching logic so the objects can not be removed immediately which increases the pressure more.
Interns is in Hadoop project, and I think the implementation is not suitable for HBase. Because we can not know how many MetricsInfo we have, it depends on the number of regions. And we can not set it unlimited because we should remove the objects whose region is split, moved, or dropped. I think we can use Guava&amp;apos;s cache with expireAfterAccess which is very simple and convenient.
So we can add a new Interns class in HBase project first, and put it to upstream later.
Moreover, in MutableHistogram#snapshot we create same Strings each time, we can create them only in the first time.