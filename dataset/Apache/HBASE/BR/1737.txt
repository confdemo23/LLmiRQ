Regions unbalanced when adding new node
When adding a new RegionServer to a cluster, the new RS will receive some regions but not enough to actually be considered balanced.
To recreate, just take an RS offline, allow regions to be reassigned, and then bring it back up.
Master will get itself into a broken, stuck state where it continuously outputs a line like this:

2009-08-03 12:54:57,812 DEBUG org.apache.hadoop.hbase.master.RegionManager: Server dn4,60020,1249329081079 will be unloaded for balance. Server load: 341 avg: 318.0, regions can be moved: 55



This line is output every 3 seconds and never stops until another RS joins/leaves the cluster.
Making this a blocker because when your new RS only gets some regions (in my case, about half as many as it should have), then all new regions will be assigned to that RS.  This basically destroys any possibility for good load distribution with new data.