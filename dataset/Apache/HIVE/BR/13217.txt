Replication for HoS mapjoin small file needs to respect dfs.replication.max
Currently Hive on Spark Mapjoin replicates small table file to a hard-coded value of 10.  See SparkHashTableSinkOperator.MIN_REPLICATION. 
When dfs.replication.max is less than 10, HoS query fails.  This constant should cap at dfs.replication.max.
Normally dfs.replication.max seems set at 512.