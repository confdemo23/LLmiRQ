NullPointerException when spark session is reused to run a mapjoin
The way to reproduce:

set hive.execution.engine=spark;

create table if not exists test(id int);

create table if not exists test1(id int);

insert into test values(1);

insert into test1 values(1);

select max(a.id) from test a ,test1 b

where a.id = b.id;


